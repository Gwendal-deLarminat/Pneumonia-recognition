{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41cb4a5f-6e31-4075-89df-db639b5f34b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import skimage.io\n",
    "import os\n",
    "import tqdm\n",
    "import glob\n",
    "import tensorflow\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "from skimage.color import grey2rgb\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Flatten, Dense, Activation, MaxPool2D, Conv2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "from typeguard import typechecked\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be3764cc-56c0-45da-9608-16032ec759e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b709af96-e60e-4b6b-9aa5-c7a4c7c106da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   validation_split = 0.2,     \n",
    "                                    rotation_range=5,\n",
    "                                    width_shift_range=0.2,\n",
    "                                    height_shift_range=0.2,\n",
    "                                    shear_range=0.2,\n",
    "                                    horizontal_flip=True,\n",
    "                                    vertical_flip=True,\n",
    "                                    fill_mode='nearest')\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  validation_split = 0.2)\n",
    "\n",
    "test_datagen  = ImageDataGenerator(rescale = 1./255\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7099d886-92cb-4502-84d9-cc0fbb43ab74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset  = train_datagen.flow_from_directory(directory = './chest_Xray/train',\n",
    "                                                   target_size = (224,224),\n",
    "                                                   class_mode = 'categorical',\n",
    "                                                   batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "711bcba9-8add-43b9-8523-3d870fbb8cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = valid_datagen.flow_from_directory(directory = './chest_Xray/val',\n",
    "                                                  target_size = (224,224),\n",
    "                                                  class_mode = 'categorical',\n",
    "                                                  batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ebfa172-2221-4185-b88e-aebc6cd2cc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dataset = test_datagen.flow_from_directory(directory = './chest_Xray/test',\n",
    "                                                  target_size = (224,224),\n",
    "                                                  class_mode = 'categorical',\n",
    "                                                  batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d92fbe1-e24f-48f9-9c47-372b7bd1c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.VGG16(input_shape=(224,224,3),include_top=False,weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29ddc42c-586a-43b3-84ec-8fb838b9aae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[:-8]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f566793-9f6a-414c-bbaa-d73d0c21b51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32,kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32,kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32,kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c6da416-cb56-4b7c-b1a4-f0b1286a95b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 25088)            100352    \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                802848    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,620,450\n",
      "Trainable params: 13,834,594\n",
      "Non-trainable params: 1,785,856\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cf50a05-bcd9-4cc5-b44f-7e1e91d40dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3deb43ad-8c80-4cf4-b795-31b14f1c6f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),  \n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "        f1_score,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "971b11ed-62a2-4c77-9722-8149eb8b99e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrd = ReduceLROnPlateau(monitor = 'val_loss',patience = 3,verbose = 1,factor = 0.50, min_lr = 1e-7)\n",
    "\n",
    "mcp = ModelCheckpoint('model.h5')\n",
    "\n",
    "es = EarlyStopping(verbose=1, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7936611-b733-4576-b562-0f87319eb85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b61c6ff0-8a87-4002-8292-d83413c5d787",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Epoch 1/5\n",
      "82/82 [==============================] - 1230s 15s/step - loss: 0.5660 - accuracy: 0.7304 - precision: 0.7304 - recall: 0.7304 - auc: 0.7900 - f1_score: 0.7313 - val_loss: 1.7781 - val_accuracy: 0.6250 - val_precision: 0.6250 - val_recall: 0.6250 - val_auc: 0.6797 - val_f1_score: 0.6250 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "82/82 [==============================] - 1194s 15s/step - loss: 0.3215 - accuracy: 0.8714 - precision: 0.8714 - recall: 0.8714 - auc: 0.9422 - f1_score: 0.8710 - val_loss: 8.8370 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_auc: 0.5000 - val_f1_score: 0.5000 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "82/82 [==============================] - 1220s 15s/step - loss: 0.2125 - accuracy: 0.9218 - precision: 0.9218 - recall: 0.9218 - auc: 0.9740 - f1_score: 0.9215 - val_loss: 1.0064 - val_accuracy: 0.6875 - val_precision: 0.6875 - val_recall: 0.6875 - val_auc: 0.8242 - val_f1_score: 0.6875 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "82/82 [==============================] - 1193s 15s/step - loss: 0.1722 - accuracy: 0.9377 - precision: 0.9377 - recall: 0.9377 - auc: 0.9806 - f1_score: 0.9375 - val_loss: 1.8718 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 0.5625 - val_auc: 0.6953 - val_f1_score: 0.5625 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "82/82 [==============================] - 1188s 14s/step - loss: 0.1928 - accuracy: 0.9214 - precision: 0.9214 - recall: 0.9214 - auc: 0.9768 - f1_score: 0.9213 - val_loss: 2.6045 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_auc: 0.6562 - val_f1_score: 0.5000 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "tf.keras.backend.clear_session()\n",
    "history=model.fit(train_dataset,validation_data=valid_dataset,epochs = 5,verbose = 1,callbacks=[lrd,mcp,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e70bbada-dfc8-4fe7-b516-817d5f1c69b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 25088)            100352    \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                802848    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,620,450\n",
      "Trainable params: 13,834,594\n",
      "Non-trainable params: 1,785,856\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "573c08cd-f9e5-4e48-ba1f-687a96ce1394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 79s 8s/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEJCAYAAAC0U81tAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhfElEQVR4nO3de9xVVZ3H8c/34SYKKIgoKoa38laSknmLcJoxNMuyMWFswsJRS9MsnbSxNCcay1Ebr6mjieUlTEm8jJccCS1TLhGKd5MQJRDQBGVU8Dd/7HVkc3yecw4P53nO2Q/ft6/9Yu+1195rnefg71msvfZaigjMzKw4WhpdATMzWzsO3GZmBePAbWZWMA7cZmYF48BtZlYwDtxmZgXjwG1mVkeSNpD0iKQ/SZoj6fspfYCkeyU9k/7sn7vmdEnPSnpK0ierluFx3GZm9SNJwEYRsVxSD+BB4CTgMGBpRJwj6TSgf0R8W9IuwA3AXsCWwG+A90fEqrbK6N7hn2I9p+69Qz37NroathY+vPM2ja6CraWZM2csjojN1uUe3fq9L2Lliqr5YsXLd0fEqDbPZ63h5emwR9oCOBQYmdInAFOAb6f0GyPiTeB5Sc+SBfGH2irDgbuDqWdfen3gC42uhq2F3z18caOrYGupdw/9ZV3vESv/j147ja6a7//+eNHAankkdQNmADsAl0TEw5I2j4gFABGxQNKglH0r4A+5y+entDY5cJuZAQiQask5UNL03PEVEXFFPkPq5hgmaRNgkqTdqpRcrmIftgO3mVmJahqvsTgihteSMSJelTQFGAUslDQ4tbYHA4tStvnAkNxlWwMvVbqvR5WYmZVI1beqt9BmqaWNpN7A3wNPApOBsSnbWODWtD8ZGC2pl6RtgR2BRyqV4Ra3mRkAgpZu9bjRYGBC6uduASZGxO2SHgImShoHzAMOB4iIOZImAo8DK4HjK40oAQduM7OMqLWrpKKImA18uJX0JcAn2rhmPDC+1jIcuM3MAKitK6QZOHCbmZXUocXdGRy4zcxK3OI2MysSucVtZlYool6jSjqcA7eZGeAWt5lZEbW4j9vMrDjqNI67Mzhwm5mVeFSJmVmR1O2V9w7nwG1mVuKuEjOzAqlx9r9m4MBtZlbiFreZWcG4xW1mViR+AcfMrFj8yruZWdG4xW1mVjzu4zYzKxi3uM3MCsYtbjOzApH7uM3MCkctDtxmZoUhQO4qMTMrEKWtABy4zcwAkFvcZmZF48BtZlYwLX44aWZWIAXq4y7Grxczsw6m1Mddbat6H2mIpPslPSFpjqSTUvpZkl6UNCttB+euOV3Ss5KekvTJamW4xW1mltSpj3sl8K2ImCmpLzBD0r3p3AUR8Z9lZe4CjAZ2BbYEfiPp/RGxqq0C3OI2M0vq0eKOiAURMTPtLwOeALaqcMmhwI0R8WZEPA88C+xVqQwHbjOzpB6Bu+x+Q4EPAw+npBMkzZZ0taT+KW0r4IXcZfOpHOgduM3MgDQdt6puwEBJ03PbMa3eTuoD3Ax8IyJeAy4DtgeGAQuA81aX/B5Rqaru4zYzY/XDyRosjojhFe8l9SAL2tdFxC0AEbEwd/5K4PZ0OB8Ykrt8a+ClSvd3i9vMLKnTqBIBVwFPRMT5ufTBuWyfAx5L+5OB0ZJ6SdoW2BF4pFIZbnGbmZXUZxz3fsA/A49KmpXSvgOMkTSMrBtkLnAsQETMkTQReJxsRMrxlUaUgAO3mVlG9RkOGBEP0vqvgDsrXDMeGF9rGQ7cZmaJ5yoxMysQIc9VYmZWOMVocDtwm5kBdevj7gwO3GZmiQO3mVnBOHBbofXq2Z07rvgGvXp0p1v3bky+74+cc8WdbNJvQ67+4VfYZvAA5i1YypdPv4q/LVvByL124swTPkPPHt156+2VfO/CX/PA9Kcb/THWWyec/QvufvAxBvbvy0O//DcAXvnb63zlO1czb8FSthk8gJ/9xzg26bdhg2vaXNIr7U2vqR+hSgpJ5+WOT5F0Vu74GElPpu0RSfvnzk1Jc9v+SdK0NPC9dG6upAfKypol6bGytP9K8+e25NKOknRxfT9p83nzrZUc+tUL+diR5zDin/6DT+yzC8N3G8rJY/+BqdOeYvjnz2bqtKc4eeyBACx5dTljvnk5+435IV/7/s/56fe/1OBPsH4bc8je/OrC49dIu2DCvYz4yAeYccuZjPjIB7hgwj0Nql1zquWtyWZpkTd14AbeBA6TNLD8hKRDyN482j8idgKOA66XtEUu25ERsTtwKXBu2S36ShqS7rVzK/dvIXst9QVgRD0+TNG8vuItAHp070aP7t2ICA76+Ie44fZsorMbbn+Yg0d+CIBHn57PXxf/DYAnnlvABj170LOH/0HXKPvtsQP9y1rT//Pb2Yw55KMAjDnko9w5ZXYjqtbUHLjrYyVwBXByK+e+DZwaEYsB0vy3E4DjW8n7EO+dJnEicETaHwPcUHb+ALK5BC5L59c7LS1i6nWn8fQ95zDl4SeZMecvDBrQl4VLXgNg4ZLX2Kx/3/dc95m/G8bsp1/grbdXdnaVrYJFS5exxcCNAdhi4Ma8/MqyBteo+Thw188lwJGSNi5L3xWYUZY2PaWXGwX8uiztV8Bhaf/TwG1l50vBfBJwSJrta73yzjvBiCPPYddPncEeu76PnbcfXPWanbbbgrO+fign//DGTqihWZ2phq0JNH3gTvPYXgucWEN2seY8ttdJmk/WOr+oLO9S4BVJo8lWqHjj3ZtIPYGDgV+n8h8GDqy1zqnvfbqk6bFyRa2XNa3Xlq/gwRnP8Il9dmHR0mVsvmk/ADbftN8arbYtB23Cz398DF898+fMfXFxo6prbRg0oO+73Vl/Xfy3Vv+1tL5zi7u+fgKMAzbKpT0O7FmWb4+UXnIksC1wPVnLvdwvU3p5N8koYGOy2b3mAvuzFt0lEXFFRAyPiOHq3rvWy5rKppv0oV+frO4b9OrByL0+wDNzF3LX1EfX6Cf9n99m/aT9+vTmlxccx9mXTObh2X9uWL2tbaNGfHCN5xMHffxDDa5Rc5Gy7sFqWzMoxNOjiFiapj0cB1ydkn8M/EjSqIhYkkaNHAV8tOzatyWdATwnaeeIeCJ3ehIwGLibbJHOkjHA0RFxA4CkjYDnJa03Y6e2GNiPS8/6Z7q1tNDSIib9ZiZ3P/gYjzz6PD/7j6/wxc/sw/yFr3DUaVcB8C9fGMG2Qzbj1KNHcerRowA47ISLWfzK8kZ+jPXWuH/7Gb+b8QxLXl3Orp86g9OOOZiTx/4DXz79an4x+SG23rw/15wzrtHVbDLN06KuRhEVV8hpKEnLI6JP2t8ceB74cUScldK+CnyDrHtkGdnKylPTuSnAKRExPR1/C9glIsalVvTw0oPNdH4o2YoUe5GtSDE0dZOUzt9C1kLvDVwMvJqr6t4RMb+1z9Cy4aDo9YEvrMuPwTrZK9O6/GjPLqd3D82otipNNRts8f7Y5ksXVs33zLkHrXNZ66qpW9yloJ32FwIblp2/jGzUR2vXjiw7Pi+3P7SV/HOB3dLhgFbOH5Y7vKZK1c2sgIrS4m7qwG1m1mmU9XMXgQO3mRnZkLRmefhYjQO3mVniwG1mViTuKjEzKxbhh5NmZgVTnHHcDtxmZklB4rYDt5kZAPLDSTOzQnEft5lZARUkbjtwm5mVuMVtZlYwBYnbDtxmZkB6AacYkbsoCymYmXUoUX0RhVpGnUgaIul+SU9ImiPppJQ+QNK9kp5Jf/bPXXO6pGclPSXpk9XKcOA2M0uk6lsNVpKtDbAzsDdwvKRdgNOA+yJiR+C+dEw6N5psvdxRwKWSulUqwIHbzCypx5qTEbEgImam/WVka9puBRwKTEjZJgCfTfuHAjdGxJsR8TzwLNmCLm1y4DYzg3cnmaqhxT2wtBh42o5p85bZylofJltwfPOIWABZcAcGpWxbAS/kLpuf0trkh5NmZqzVCziLa1m6TFIf4GbgGxHxWoV7t3ai4pqSbnGbmSX16CpJ9+lBFrSvi4hbUvJCSYPT+cHAopQ+HxiSu3xr4KVK93fgNjNL6jSqRMBVwBMRcX7u1GRgbNofC9yaSx8tqZekbYEdgUcqleGuEjMzqOdCCvsB/ww8KmlWSvsOcA4wUdI4YB5wOEBEzJE0EXicbETK8RGxqlIBDtxmZmTjuOvxAk5EPEjr/dYAn2jjmvHA+FrLcOA2M0sK8uKkA7eZWUlLQSK3A7eZGVlr2wspmJkVTEHitgO3mVlJUWYHbDNwS7qICm/vRMSJHVIjM7MGKUjcrtjint5ptTAzazCRDQksgjYDd0RMyB9L2igiXu/4KpmZNUZR+rirvvIuaR9Jj5NNTYik3SVd2uE1MzPrTKrPQgqdoZa5Sn4CfBJYAhARfwJGdGCdzMw6ncjGcVfbmkFNo0oi4oWyp60V36M3MyuiJonLVdUSuF+QtC8QknoCJ5K6TczMupKiDAespavkOOB4shUZXgSGpWMzsy6jltVvmiWuV21xR8Ri4MhOqIuZWUN1a5bIXEUto0q2k3SbpJclLZJ0q6TtOqNyZmadqV4r4HS0WrpKrgcmAoOBLYGbgBs6slJmZp0tG1VSfWsGtQRuRcTPI2Jl2n5BlYUszcwKp4bWdrO0uCvNVTIg7d4v6TTgRrKAfQRwRyfUzcysUzVJXK6q0sPJGWSBuvRRjs2dC+DfO6pSZmaN0Cwt6moqzVWybWdWxMyskQR0a5ZO7CpqenNS0m7ALsAGpbSIuLajKmVm1gjFCNs1BG5JZwIjyQL3ncBBwIOAA7eZdRlScdacrGVUyT+SLSn/14j4MrA70KtDa2Vm1gBd5s1JYEVEvCNppaR+wCLAL+CYWZdT+IeTOdMlbQJcSTbSZDnwSEdWysysEQoSt2uaq+Rrafenku4C+kXE7I6tlplZ55JU/FElkvaodC4iZnZMlczMGqMrdJWcV+FcAH9X57p0TWqBnr0bXQtbC2+vfKfRVbAGqWW0RjOo9ALOAZ1ZETOzRhL1a3FLuho4BFgUEbultLOAfwFeTtm+ExF3pnOnA+PIVhc7MSLurnT/ovyCMTPrcHWcHfAaYFQr6RdExLC0lYL2LsBoYNd0zaWSulWsZ83VMDPrwqTslfdqWy0iYiqwtMaiDwVujIg3I+J54Flgr0oXOHCbmSWdMB/3CZJmS7paUv+UthXwQi7P/JTWdj2rlaLMFyV9Lx1vI6nibwMzsyKq8c3JgZKm57Zjarz9ZcD2ZOv2LmD1AJDWfh1UXPOglhdwLgXeIRtFcjawDLgZ+EhtdTUza37ZCjg1NakXR8Twtb1/RCx8tyzpSuD2dDgfGJLLujXwUqV71dJV8tGIOB74v1T4K0DPtamwmVkRtNSwtZekwbnDzwGPpf3JwGhJvSRtC+xIlbfTa2lxv52ecEYqfDOyFriZWZdSr/dvJN1ANqvqQEnzgTOBkZKGkcXSuaTFaSJijqSJwOPASuD4iFhV6f61BO4LgUnAIEnjyWYLPKM9H8bMrFnV85X3iBjTSvJVFfKPB8bXev9a5iq5TtIMsqldBXw2Ip6otQAzs6IoyFQlNS2ksA3wBnBbPi0i5nVkxczMOtNaPJxsuFq6Su5g9aLBGwDbAk+RveVjZtZlFCRu19RV8sH8cZo18Ng2spuZFVN9XrDpFDUtFpwXETMleQy3mXU5KshywbX0cX8zd9gC7MHq2a3MzLoEAd0LMglILS3uvrn9lWR93jd3THXMzBqnKyykQHrxpk9EnNpJ9TEza4hsVEmja1GbSkuXdY+IlZWWMDMz6zLUNUaVPELWnz1L0mTgJuD10smIuKWD62Zm1qm60jjuAcASstkBS+O5A3DgNrMuQ0C3LvBwclAaUfIYqwN2ScW5Ys3Mike0dIHhgN2APrRjkm8zs6LJFgtudC1qUylwL4iIszutJmZmjdRF3pwsyEcwM6uPrvBw8hOdVgszswbrEl0lEVHr0vJmZl1CvRZS6GhrPcmUmVlXJNZtTcnO5MBtZgbpzUm3uM3MCqUYYduB28wM6HpLl5mZrReKEbYduM3MEtHiUSVmZsXhUSVmZgXkUSVmZgVTjLDtwG1mlvE4bjOzYhHQrSCBuyh98WZmHU41bDXdR7pa0iJJj+XSBki6V9Iz6c/+uXOnS3pW0lOSPlnt/g7cZmaJVH2r0TXAqLK004D7ImJH4L50jKRdgNHArumaSyV1q3RzB24zM0rDAVV1q0VETAXKZ1g9FJiQ9icAn82l3xgRb0bE88CzwF6V7u/AbWaW1LHF3ZrNI2IBQPpzUErfCnghl29+SmuTH06amQEgVFuLeqCk6bnjKyLiinUq+L0qruvrwG1mxlqNKlkcEcPbUcRCSYMjYoGkwcCilD4fGJLLtzXwUqUbuavEzAzSOO4O7SqZDIxN+2OBW3PpoyX1krQtsCPwSKUbucVtZpbUaxi3pBuAkWTdKvOBM4FzgImSxgHzgMMBImKOpInA48BK4PiIWFXp/g7cZmZJjX3cVUXEmDZOtboIe0SMB8bXen8HbjMzSgspNLoWtXHgNjNLvAKOmVnB1KurpKM5cFurthq0MZd9dzSDBvTlnQgm3Powl9/0ILvtMJjzTv08fXr3ZN6CVzjm+9ez7I03GbJFfx6+/lSenfcyANPn/IVvnntLgz/F+uukH1zHvb+fw8D+fZl63ekA/MsZP+PZedkItNeWraBf397cf+23G1nNpuKuEkDSKuDRVMYTwNiIeCOXXnJjRJwjaQrQpzQ+UtJw4D8jYqSko4DhEXFC7v5TgFMiYrqkucALEfGx3PlZQPeI2C0d7w+cD/RLWc4vDZqXdBbwr8DQiFiU0pZHRJ/8vqSh6bM8lav/+RFx7Tr9sJrQylXvcMZFtzP76Rfps2Ev7r/qJKZMe5r/Ou1wvnvx7fx+1p858lMf4etHjuSHV94NwNwXlzDiqAsaXHMDGP2pjzLu8BGccPYv3k278gdffnf/exdOot9GGzSiak2s5hdwGq4jx3GviIhhKXC+BRxXll7azsldM0jSQe0sr6+kIQCSds6fkLQFcD1wXETsBOwPHCvpU7lsi4Fv1VDOc2X173JBG2DhkmXMfvpFAJa/8SZP/2URgzfbmB222Yzfz/ozAFOmPc2nP/7BRlbT2rDPh3dgk34btnouIph83x857MA9O7lWTa7jx3HXTWe9gPMAsEMN+c4FzmhnGROBI9L+GOCG3LnjgWsiYiZARCwma2GflstzNXCEpAHtLL/LGrJFfz6045bMmDOPJ//8Vw7af1cADj1gd7bafON3820zeAC//dk3uP3i49hn920bVV2r4g+znmOzAX3Zbsig6pnXM/Wa1rWjdXjgltQdOIjV3SO9Jc3KbUfksj8EvCnpgHYU9SvgsLT/aeC23LldgRll+aen9JLlZMH7pCrlbF9W/4+VZ5B0jKTpkqbHyjfW6kM0m4169+Ta8V/i9Asns+yNNznhhxM5+vP7cv9VJ9Fnw168/Xb2nsDCJa/xwcPG8/Ev/4R/u+g2rjzzn+i7Ya8G195ac8u9M/jcP7i1Xa70ynu1rRl05MPJ3qmfGbIW91Vpf0VEDKtw3Q/IWt35pyZtTbiST18KvCJpNFk/dD5iqo17lKddCMySdF6F+j1Xpf6kvvMrAFo22qLiZDHNrHu3FiaM/xI33fNHbv9tNh/8M/Ne5vMnXwnA9kMGcuC+OwHw1tureOvt7Ef+p6de5PkXl7D9Npsx68n5jam8tWrlylXcMWU2v7nmlEZXpTk1R1yuqjP6uIdFxNcj4q1aLoqI/wU2APbOJS8B+pdlHUDWL533S+AS1uwmAZgDlE8KsyfZK6b5sl8l6wv/Wi117eouOv0LPP2XRVz6y6nvpg3cZCMgW5vvlLF/z89+/QcANt1kI1rSI/n3bTmA7YYMZO6LSzq/0lbR1GlPseP7BrHloPL/nQxKjycr/9cMmnU44Hjgp8Cf0/E04GJJW0TEX9OIk16sOYctwCRgMHA3sGUu/RLgYUm3RMQsSZsCPwLObqXs81N5zfqz6RR7f2goow/akznPLmDqNScD8O+X/w/bbT2Qow/bF4Dbf/so190xDYB9h23H6UcfyKqV77DqnXf41rk38+qyFQ2r//ru2O9dw+9mPsvSV5ez+2e+y78efTBHfmYfJv1mprtJKmiSnpCqGhGc8l0oAHdFRP4hIRFxp6SXc8cLJZ0E3Cmphaw/ekxEvFN23TKygLzGas1pGsUvAldK6kv2D6KfRES+H7yUd7GkScDJbdR/+7L6Xx0RF1b70EXzh9lz6b/fqa2eu/ymB9+TdtuUR7ltyqOt5LZGuPzso1pNv+i7X+zcihRMQeJ2xwXu0hjoVtJbXUstIkaWHe9Zdnwrq6dBLL92aCtpc4HdcsdTgY+0cf1ZZcffBL6ZO+6Tu2fv1u5hZl1AQSL3et0dYGZWInmuEjOzwilG2HbgNjNbrSCR24HbzAwo0lwlDtxmZklBurgduM3MIM1F4sBtZlYs7ioxMysYt7jNzAqmIHHbgdvMDGiuCbercOA2M0vcx21mViBeLNjMrIgcuM3MisVdJWZmBePhgGZmBVOvuC1pLrAMWAWsjIjhkgaQLa84FJgLfCEiXmnP/Tt8lXczs8JQDVvtDkhr7pbWuz0NuC8idgTuS8ft4sBtZsbqhRSqbevgUGBC2p8AfLa9N3LgNjNL6tjgDuAeSTMkHZPSNo+IBZCtgwsMam893cdtZlZSW2QeKGl67viKiLiiLM9+EfGSpEHAvZKerFcVwYHbzCypeSGFxbl+61ZFxEvpz0WSJgF7AQslDY6IBZIGA4vaW1N3lZiZJVL1rfo9tJGkvqV94EDgMWAyMDZlGwvc2t56usVtZkZdF1LYHJik7Gbdgesj4i5J04CJksYB84DD21uAA7eZWVKPNycj4s/A7q2kLwE+sc4F4MBtZvYuvzlpZlYwBYnbDtxmZgDU+PCxGThwm5m9qxiR24HbzAwvpGBmVkjuKjEzKxgvpGBmVjTFiNsO3GZmJQWJ2w7cZmZQ+1wkzcCB28wsUUEitwO3mVlSjLDtwG1m9q6CNLgduM3MMjUvpNBwDtxmZtR1Pu4O58BtZpY4cJuZFYy7SszMisTjuM3MikV4OKCZWfEUJHI7cJuZJe7jNjMrGC+kYGZWNA7cZmbF4q4SM7MCKdKbk4qIRtehS5P0MvCXRtejgwwEFje6Elazrvx9vS8iNluXG0i6i+xnVM3iiBi1LmWtKwduazdJ0yNieKPrYbXx99V1tDS6AmZmtnYcuM3MCsaB29bFFY2ugK0Vf19dhPu4zcwKxi1uM7OCceBeT0gKSefljk+RdFbu+BhJT6btEUn7585NkfSUpD9JmiZpWO7cXEkPlJU1S9JjZWn/JelFSS25tKMkXVzfT1oMklaVfk6SbpK0YVl6aTstpU+RND13/XBJU9L+e36OKf/wtF/1O5K0f/reS38HjsmdO0vSG5IG5dKWl+9LGippRVn9v1SXH5itwYF7/fEmcJik94xTlXQIcCywf0TsBBwHXC9pi1y2IyNid+BS4NyyW/SVNCTda+dW7t8CfA54ARhRjw/TBayIiGERsRvwFtnPPJ9e2s7JXTNI0kHtLK/N7yh9z9cDx6Xvf3/gWEmfymVbDHyrhnKeK6v/te2sr1XgwL3+WEn2cOrkVs59Gzg1IhYDRMRMYAJwfCt5HwK2KkubCByR9scAN5SdPwB4DLgsnbc1PQDsUEO+c4Ez2llGpe/oeOCa9L2T/h78K3BaLs/VwBGSBrSzfKsjB+71yyXAkZI2LkvfFZhRljY9pZcbBfy6LO1XwGFp/9PAbWXnS4FiEnCIpB5rV+2uS1J34CDg0ZTUu6yr4Yhc9oeANyUd0I6iKn1HtXz/y8mC90lVytm+rP4fa0ddrQrPVbIeiYjXJF0LnAisqJJdQH7I0XWSNgK6AXuU5V0KvCJpNPAE8Ma7N5F6AgcDJ0fEMkkPAwcCd6zThym+3pJmpf0HgKvS/oqIGFbhuh+Qtbq/nUtra2hYPr3N74j3ftdt3fdCYFb+WUkrnqtSf6sDt7jXPz8BxgEb5dIeB/Ysy7dHSi85EtiWrC/0klbu+8uUXt5NMgrYGHhU0lyy/lN3l6zZl/31iHirlosi4n+BDYC9c8lLgP5lWQfw3nlJ2vqO5gDlr8LvyZrfPxHxKtn3/7Va6modx4F7PRMRS8n6O8flkn8M/EjSpgBp1MhRZA8i89e+Tdba27uVh5CT0n3uLksfAxwdEUMjYihZ8D+wNIrC2mU8WR90yTRgv9LD5DSapBfZw+C8tr6jS4CjSqOF0t+DH6W85c4ne5Dtf603kH/466fzgBNKBxExWdJWwO8lBbAM+GJELCi/MCJWpH8qn0Iu+EfEMrL/2VGaGzMF50+S/Y9eyve6pAfJ+lkhCxifzRWxd0TMr8eHLKh8FwrAXRGRf0hIRNyZZp0sHS+UdBJwZxrBsxwYExHvlF33nu8opS+Q9EXgSkl9ybpOfhIR5c8qiIjFkibR+kNuSH3cueOrI+LCah/a1o7fnDQzKxh3lZiZFYwDt5lZwThwm5kVjAO3mVnBOHCbmRWMA7c1XFsz5bXzXtdI+se0/9+SdqmQd6SkfdtRxtw2JutqNb0sz/JK51vJf5akU9a2jta1OXBbM2hrpjwAJHVrz00j4uiIeLxClpHAWgdus0Zz4LZm8wCwQ2oN3y/perLX5btJOlfZfOCzJR0LoMzFkh6XdAeQnzM6Pyf1KEkzlc0pfp+koWS/IE4uTYYkaTNJN6cypknaL127qaR7JP1R0uVkL6hUJOnXkmZImpOf2zqdOy/V5T5Jm6W07SXdla55QNJOdflpWpfkNyetaeRmyrsrJe0F7BYRz6fg97eI+IikXsDvJN0DfBj4APBBYHOy+TWuLrvvZsCVwIh0rwERsVTST4HlEfGfKd/1wAUR8aCkbcheDd8ZOBN4MCLOTnNUrxGI2/CVVEZvYJqkmyNiCdkcMTMj4luSvpfufQLZlLvHRcQzkj5KNt3A37Xjx2jrAQduawatzZS3L/BIRDyf0g8EPlTqvyabuGpHsoUZboiIVcBLkv63lfvvDUwt3SvN19Kavwd2yb0O3i+9Aj6CNCVqRNwh6ZUaPtOJkj6X9oekui4B3iGb7AngF8Atkvqkz3tTruxeNZRh6ykHbmsG75nKNAWw1/NJwNcj4u6yfAfT9rSm+WtrmduhBdgnItaY8jbVpea5ISSNJPslsE9EvKFsibEN2sgeqdxXPR2q1cp93FYUdwNfVVqEQdL7lc0PPhUYnfrAB5OttlPuIeDjkrZN15ZWcVkG9M3lu4fc5FtavbbmVLJpbVG2dFj5FKrlNgZeSUF7J9acgrUFKP2r4Z/IumBeA56XdHgqQ5J2r1KGrcccuK0o/pus/3qmskVuLyf7F+Mk4BmyFWQuA35bfmFEvEzWL32LpD+xuqviNuBzWr1Sy4nA8PTw83FWj275PjBC0kyyLpt5Vep6F9Bd0mzg34E/5M69DuwqaQZZH/bZKf1IYFyq3xzg0Bp+Jrae8uyAZmYF4xa3mVnBOHCbmRWMA7eZWcE4cJuZFYwDt5lZwThwm5kVjAO3mVnBOHCbmRXM/wOOKX55fSWf0AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Convertir les labels en un format numérique\n",
    "labels = ['NORMAL', 'PNEUMONIE']*312\n",
    "\n",
    "le = LabelEncoder()\n",
    "labels_encoded = le.fit_transform(labels)\n",
    "\n",
    "predictions = model.predict(test_dataset, workers=2, max_queue_size=10)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "\n",
    "# Calculer la matrice de confusion\n",
    "cm = confusion_matrix(labels_encoded, predicted_classes)\n",
    "\n",
    "# Afficher la matrice de confusion sous forme de heatmap\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['NORMAL', 'PENUMONIE'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "780a020a-998c-41fe-bbbb-4ebd1e7922ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 76s 7s/step - loss: 2.5363 - accuracy: 0.4183 - precision: 0.4183 - recall: 0.4183 - auc: 0.5407 - f1_score: 0.4177\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23507f0-88e6-4d5a-a014-8ae09ddc046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model_accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9455a03-5775-4e74-af21-2f3f25690303",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
